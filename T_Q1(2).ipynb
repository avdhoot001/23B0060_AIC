{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow opencv-python-headless\n"
      ],
      "metadata": {
        "id": "0C6hwWpAHzWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Load Pascal VOC dataset\n",
        "dataset, info = tfds.load(\"voc/2007\", with_info=True)\n",
        "train_dataset = dataset['train']\n",
        "val_dataset = dataset['validation']\n"
      ],
      "metadata": {
        "id": "AyUpUOA3k4r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "\n",
        "def preprocess_data(data):\n",
        "    image = tf.image.resize(data['image'], (IMG_SIZE, IMG_SIZE))\n",
        "    image = image / 255.0  # Normalize to [0, 1]\n",
        "    label = data['objects']['label']\n",
        "    bbox = data['objects']['bbox']\n",
        "    return image, {'label': label, 'bbox': bbox}\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess_data)\n",
        "val_dataset = val_dataset.map(preprocess_data)\n"
      ],
      "metadata": {
        "id": "jCdmghTZk4tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load VGG16 base model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "# Freeze the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "\n",
        "# Bounding box output\n",
        "bbox_output = Dense(4, activation='sigmoid', name='bbox')(x)\n",
        "\n",
        "# Classification output\n",
        "class_output = Dense(info.features['objects']['label'].num_classes, activation='softmax', name='label')(x)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=base_model.input, outputs=[bbox_output, class_output])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss={'bbox': 'mse', 'label': 'sparse_categorical_crossentropy'},\n",
        "              metrics={'bbox': 'mse', 'label': 'accuracy'})\n"
      ],
      "metadata": {
        "id": "c_ZJo_u6k4vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set batch size and epochs\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "# Prepare the training and validation datasets\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_dataset,\n",
        "                    validation_data=val_dataset,\n",
        "                    epochs=EPOCHS)\n"
      ],
      "metadata": {
        "id": "9DCmg-5Ek4xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze some layers in the base model\n",
        "for layer in base_model.layers[-4:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile the model with a lower learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "              loss={'bbox': 'mse', 'label': 'sparse_categorical_crossentropy'},\n",
        "              metrics={'bbox': 'mse', 'label': 'accuracy'})\n",
        "\n",
        "# Continue training\n",
        "history_fine = model.fit(train_dataset,\n",
        "                         validation_data=val_dataset,\n",
        "                         epochs=EPOCHS)\n"
      ],
      "metadata": {
        "id": "GhDKZCHmk4zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9D10f4CJk41b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nmXtZoTAk44f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XpjDGnCyk47S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}